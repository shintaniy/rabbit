{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lecture_chap1_exercise_public.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Ht1-DGiJAM7f","colab_type":"text"},"cell_type":"markdown","source":["# 演習 Sequence-to-Sequence (Seq2Seq) モデル"]},{"metadata":{"id":"lImUIx2SAM7h","colab_type":"text"},"cell_type":"markdown","source":["Sequence-to-Sequence (Seq2Seq) モデルは、系列を入力として系列を出力するモデルです。\n","\n","入力系列をRNNで固定長のベクトルに変換(= Encode)し、そのベクトルを用いて系列を出力(= Decode)することから、Encoder-Decoder モデルとも呼ばれます。\n","\n","RNNの代わりにLSTMやGRUでも可能です。\n","\n","機械翻訳のほか、文書要約や対話生成にも使われます。<br>\n","今回は機械翻訳を例にとって解説していきます。"]},{"metadata":{"id":"V4sqRdFNGAIN","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"AlrUn0gcNevH","colab_type":"code","outputId":"3ad237b3-a17d-42ef-bfd7-c7f774b8343f","executionInfo":{"status":"ok","timestamp":1552901663422,"user_tz":-540,"elapsed":5308,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n","import torch\n","print(torch.__version__)\n","print(torch.cuda.is_available())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0.4.0\n","True\n"],"name":"stdout"}]},{"metadata":{"id":"55_hatEGIB3N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2451},"outputId":"29bf8a86-0ec2-4080-96f4-b0419b390fde","executionInfo":{"status":"ok","timestamp":1552901683540,"user_tz":-540,"elapsed":25396,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}}},"cell_type":"code","source":["! wget https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n","! mkdir images data\n","\n","# data取得\n","! wget https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en -P data/\n","! wget https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja -P data/\n","! wget https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en -P data/\n","! wget https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja -P data/\n","! wget https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en -P data/\n","! wget https://www.dropbox.com/s/ak53qirssci6f1j/train.ja -P data/"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2019-03-18 09:34:24--  https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/9narw5x4uizmehh/utils.py [following]\n","--2019-03-18 09:34:24--  https://www.dropbox.com/s/raw/9narw5x4uizmehh/utils.py\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucfea5b343747de9552b607fe55f.dl.dropboxusercontent.com/cd/0/inline/AdTKJD577nZU5lLN7QTEoaxlZM6PTv4gLwHWzYs94nZuV6JO9mHCXeLec0pLvt9OIXjsflMHUH77JdGx--xHERxrUiS8JasYdlcAX7M0Y1-UWoidAYicOnBlVfarmPr5iDc/file# [following]\n","--2019-03-18 09:34:25--  https://ucfea5b343747de9552b607fe55f.dl.dropboxusercontent.com/cd/0/inline/AdTKJD577nZU5lLN7QTEoaxlZM6PTv4gLwHWzYs94nZuV6JO9mHCXeLec0pLvt9OIXjsflMHUH77JdGx--xHERxrUiS8JasYdlcAX7M0Y1-UWoidAYicOnBlVfarmPr5iDc/file\n","Resolving ucfea5b343747de9552b607fe55f.dl.dropboxusercontent.com (ucfea5b343747de9552b607fe55f.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:6031:6::a27d:5106\n","Connecting to ucfea5b343747de9552b607fe55f.dl.dropboxusercontent.com (ucfea5b343747de9552b607fe55f.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 949 [text/plain]\n","Saving to: ‘utils.py.1’\n","\n","utils.py.1          100%[===================>]     949  --.-KB/s    in 0s      \n","\n","2019-03-18 09:34:25 (108 MB/s) - ‘utils.py.1’ saved [949/949]\n","\n","mkdir: cannot create directory ‘images’: File exists\n","mkdir: cannot create directory ‘data’: File exists\n","--2019-03-18 09:34:28--  https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/o4kyc52a8we25wy/dev.en [following]\n","--2019-03-18 09:34:28--  https://www.dropbox.com/s/raw/o4kyc52a8we25wy/dev.en\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucbe420b70f0bfb53409441c0005.dl.dropboxusercontent.com/cd/0/inline/AdRXf6MQrzqDiREWYVc0mtMerPm1eMCGGUOemE5XklANW5PjZ8PN0wCjd25Ha8K68fUUdop67D_kQzJ8Mx5jrhulV6CJUIXlOrlEmngF8GBpawYAwNEUXqvq6pkyMYm4r9c/file# [following]\n","--2019-03-18 09:34:29--  https://ucbe420b70f0bfb53409441c0005.dl.dropboxusercontent.com/cd/0/inline/AdRXf6MQrzqDiREWYVc0mtMerPm1eMCGGUOemE5XklANW5PjZ8PN0wCjd25Ha8K68fUUdop67D_kQzJ8Mx5jrhulV6CJUIXlOrlEmngF8GBpawYAwNEUXqvq6pkyMYm4r9c/file\n","Resolving ucbe420b70f0bfb53409441c0005.dl.dropboxusercontent.com (ucbe420b70f0bfb53409441c0005.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:6031:6::a27d:5106\n","Connecting to ucbe420b70f0bfb53409441c0005.dl.dropboxusercontent.com (ucbe420b70f0bfb53409441c0005.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 17054 (17K) [text/plain]\n","Saving to: ‘data/dev.en.1’\n","\n","dev.en.1            100%[===================>]  16.65K  --.-KB/s    in 0s      \n","\n","2019-03-18 09:34:29 (190 MB/s) - ‘data/dev.en.1’ saved [17054/17054]\n","\n","--2019-03-18 09:34:30--  https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/kdgskm5hzg6znuc/dev.ja [following]\n","--2019-03-18 09:34:31--  https://www.dropbox.com/s/raw/kdgskm5hzg6znuc/dev.ja\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucf6c93f99737ab4c05847242f19.dl.dropboxusercontent.com/cd/0/inline/AdQ2No9h5cqeB5baJQEaER4tBEtA7RSUY8ekd2b752Oj0ELiTsshRt16V99gjTImwFzWjzaYj1inoNDkdJauTXtrXXTLGCkdVHHLhyYpPJaDbjFln3txRfSiEAH4YT5TaNE/file# [following]\n","--2019-03-18 09:34:31--  https://ucf6c93f99737ab4c05847242f19.dl.dropboxusercontent.com/cd/0/inline/AdQ2No9h5cqeB5baJQEaER4tBEtA7RSUY8ekd2b752Oj0ELiTsshRt16V99gjTImwFzWjzaYj1inoNDkdJauTXtrXXTLGCkdVHHLhyYpPJaDbjFln3txRfSiEAH4YT5TaNE/file\n","Resolving ucf6c93f99737ab4c05847242f19.dl.dropboxusercontent.com (ucf6c93f99737ab4c05847242f19.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:6031:6::a27d:5106\n","Connecting to ucf6c93f99737ab4c05847242f19.dl.dropboxusercontent.com (ucf6c93f99737ab4c05847242f19.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27781 (27K) [text/plain]\n","Saving to: ‘data/dev.ja.1’\n","\n","dev.ja.1            100%[===================>]  27.13K  --.-KB/s    in 0.02s   \n","\n","2019-03-18 09:34:31 (1.52 MB/s) - ‘data/dev.ja.1’ saved [27781/27781]\n","\n","--2019-03-18 09:34:33--  https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/gyyx4gohv9v65uh/test.en [following]\n","--2019-03-18 09:34:34--  https://www.dropbox.com/s/raw/gyyx4gohv9v65uh/test.en\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc65be317223f825134f10d1f95b.dl.dropboxusercontent.com/cd/0/inline/AdQRY5tD53KQy2i0h4RvmFizK2dUXqmNs1mYBFhk4Q9XuCKifo6W9srLY196Z0yfpErdObp1HBjcuRu-ljvGhRDHAEr2eyapgGafIPDz8p4DNjhkZdcIk5JbnYhJN706Iw0/file# [following]\n","--2019-03-18 09:34:34--  https://uc65be317223f825134f10d1f95b.dl.dropboxusercontent.com/cd/0/inline/AdQRY5tD53KQy2i0h4RvmFizK2dUXqmNs1mYBFhk4Q9XuCKifo6W9srLY196Z0yfpErdObp1HBjcuRu-ljvGhRDHAEr2eyapgGafIPDz8p4DNjhkZdcIk5JbnYhJN706Iw0/file\n","Resolving uc65be317223f825134f10d1f95b.dl.dropboxusercontent.com (uc65be317223f825134f10d1f95b.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:6031:6::a27d:5106\n","Connecting to uc65be317223f825134f10d1f95b.dl.dropboxusercontent.com (uc65be317223f825134f10d1f95b.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 17301 (17K) [text/plain]\n","Saving to: ‘data/test.en.1’\n","\n","test.en.1           100%[===================>]  16.90K  --.-KB/s    in 0s      \n","\n","2019-03-18 09:34:34 (212 MB/s) - ‘data/test.en.1’ saved [17301/17301]\n","\n","--2019-03-18 09:34:36--  https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/hotxwbgoe2n013k/test.ja [following]\n","--2019-03-18 09:34:36--  https://www.dropbox.com/s/raw/hotxwbgoe2n013k/test.ja\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc6b72ad2dce7c222b57f564a6b8.dl.dropboxusercontent.com/cd/0/inline/AdTyjsPlCbaPk7N0hQze99cCHVkvvOI5ld2cqLmjFeghKmutr-OthqXjLgvxunfC6l4CIsKc9o6Ml-NCJs6s0p-gwQ0FDoISuSYFxFbBxulX80CZvhxVdGDK2lSjUYR8h4w/file# [following]\n","--2019-03-18 09:34:36--  https://uc6b72ad2dce7c222b57f564a6b8.dl.dropboxusercontent.com/cd/0/inline/AdTyjsPlCbaPk7N0hQze99cCHVkvvOI5ld2cqLmjFeghKmutr-OthqXjLgvxunfC6l4CIsKc9o6Ml-NCJs6s0p-gwQ0FDoISuSYFxFbBxulX80CZvhxVdGDK2lSjUYR8h4w/file\n","Resolving uc6b72ad2dce7c222b57f564a6b8.dl.dropboxusercontent.com (uc6b72ad2dce7c222b57f564a6b8.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:6031:6::a27d:5106\n","Connecting to uc6b72ad2dce7c222b57f564a6b8.dl.dropboxusercontent.com (uc6b72ad2dce7c222b57f564a6b8.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27793 (27K) [text/plain]\n","Saving to: ‘data/test.ja.1’\n","\n","test.ja.1           100%[===================>]  27.14K  --.-KB/s    in 0.02s   \n","\n","2019-03-18 09:34:36 (1.51 MB/s) - ‘data/test.ja.1’ saved [27793/27793]\n","\n","--2019-03-18 09:34:38--  https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/5lsftkmb20ay9e1/train.en [following]\n","--2019-03-18 09:34:38--  https://www.dropbox.com/s/raw/5lsftkmb20ay9e1/train.en\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucc39ab609e556a366572ae14474.dl.dropboxusercontent.com/cd/0/inline/AdR7XnL6As-FXghyJAVHD53GRNrACGriwlJmnANYueejQsjnfW0Him2eBhXrB-XXIsndTL3iijjUGu7JO-FigKBnXrT2cq3YG2deir-p075XcMriGPFM0K2FnSP-ZsMMgM8/file# [following]\n","--2019-03-18 09:34:38--  https://ucc39ab609e556a366572ae14474.dl.dropboxusercontent.com/cd/0/inline/AdR7XnL6As-FXghyJAVHD53GRNrACGriwlJmnANYueejQsjnfW0Him2eBhXrB-XXIsndTL3iijjUGu7JO-FigKBnXrT2cq3YG2deir-p075XcMriGPFM0K2FnSP-ZsMMgM8/file\n","Resolving ucc39ab609e556a366572ae14474.dl.dropboxusercontent.com (ucc39ab609e556a366572ae14474.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n","Connecting to ucc39ab609e556a366572ae14474.dl.dropboxusercontent.com (ucc39ab609e556a366572ae14474.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1701356 (1.6M) [text/plain]\n","Saving to: ‘data/train.en.1’\n","\n","train.en.1          100%[===================>]   1.62M  6.65MB/s    in 0.2s    \n","\n","2019-03-18 09:34:39 (6.65 MB/s) - ‘data/train.en.1’ saved [1701356/1701356]\n","\n","--2019-03-18 09:34:41--  https://www.dropbox.com/s/ak53qirssci6f1j/train.ja\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/ak53qirssci6f1j/train.ja [following]\n","--2019-03-18 09:34:41--  https://www.dropbox.com/s/raw/ak53qirssci6f1j/train.ja\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uca70d4c18fdcf55db881929d9f2.dl.dropboxusercontent.com/cd/0/inline/AdSCzbk00yR6wn5lFaKYgyXwSoZC95Y8L8iClinlIBceQZ9abDc_jM8LHjkFoQkzggYtgHSBan4kdpYnJxOrXE3NEkgNF44kxbwe34Cqkt-mZedzX_v_OI05KkcvleTiG3E/file# [following]\n","--2019-03-18 09:34:41--  https://uca70d4c18fdcf55db881929d9f2.dl.dropboxusercontent.com/cd/0/inline/AdSCzbk00yR6wn5lFaKYgyXwSoZC95Y8L8iClinlIBceQZ9abDc_jM8LHjkFoQkzggYtgHSBan4kdpYnJxOrXE3NEkgNF44kxbwe34Cqkt-mZedzX_v_OI05KkcvleTiG3E/file\n","Resolving uca70d4c18fdcf55db881929d9f2.dl.dropboxusercontent.com (uca70d4c18fdcf55db881929d9f2.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:6031:6::a27d:5106\n","Connecting to uca70d4c18fdcf55db881929d9f2.dl.dropboxusercontent.com (uca70d4c18fdcf55db881929d9f2.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2784447 (2.7M) [text/plain]\n","Saving to: ‘data/train.ja.1’\n","\n","train.ja.1          100%[===================>]   2.66M  7.40MB/s    in 0.4s    \n","\n","2019-03-18 09:34:42 (7.40 MB/s) - ‘data/train.ja.1’ saved [2784447/2784447]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"xp5QEw8CICiO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"657969e8-8c60-4238-8833-bcd3a205fc70","executionInfo":{"status":"ok","timestamp":1552901686604,"user_tz":-540,"elapsed":28442,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}}},"cell_type":"code","source":["! ls data"],"execution_count":8,"outputs":[{"output_type":"stream","text":["dev.en\t  dev.ja    test.en    test.ja\t  train.en    train.ja\n","dev.en.1  dev.ja.1  test.en.1  test.ja.1  train.en.1  train.ja.1\n"],"name":"stdout"}]},{"metadata":{"id":"_HauAB3uAM7i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1994f313-62ad-4c97-bb12-1f3be50fe0bf","executionInfo":{"status":"ok","timestamp":1552901686605,"user_tz":-540,"elapsed":28426,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}}},"cell_type":"code","source":["import random\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from nltk import bleu_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n","from utils import Vocab\n","\n","# デバイスの設定\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","torch.manual_seed(1)\n","random_state = 42\n","\n","print(torch.__version__)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["0.4.0\n"],"name":"stdout"}]},{"metadata":{"id":"pAmQOdx0AM7o","colab_type":"text"},"cell_type":"markdown","source":["# 1.データセットの準備\n","英語-日本語の対訳コーパスである、Tanaka Corpus ( http://www.edrdg.org/wiki/index.php/Tanaka_Corpus )を使います。<br>\n","今回はそのうちの一部分を取り出したsmall_parallel_enja: 50k En/Ja Parallel Corpus for Testing SMT Methods ( https://github.com/odashi/small_parallel_enja )を使用します。\n","\n","train.enとtrain.jaの中身を見てみましょう。"]},{"metadata":{"id":"gVxFp2MmAM7p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"5733fd2b-b684-4619-ebfa-20be3a814d48","executionInfo":{"status":"ok","timestamp":1552901689353,"user_tz":-540,"elapsed":31158,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}}},"cell_type":"code","source":["! head -10 data/train.en"],"execution_count":10,"outputs":[{"output_type":"stream","text":["i can 't tell who will arrive first .\n","many animals have been destroyed by men .\n","i 'm in the tennis club .\n","emi looks happy .\n","please bear this fact in mind .\n","she takes care of my children .\n","we want to be international .\n","you ought not to break your promise .\n","when you cross the street , watch out for cars .\n","i have nothing to live for .\n"],"name":"stdout"}]},{"metadata":{"id":"jSgmTKl7AM7u","colab_type":"code","outputId":"138a90b8-9448-4bd7-ab69-b85c8c100abb","executionInfo":{"status":"ok","timestamp":1552901692300,"user_tz":-540,"elapsed":34090,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"cell_type":"code","source":["! head -10 ./data/train.ja"],"execution_count":11,"outputs":[{"output_type":"stream","text":["誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n","多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n","私 は テニス 部員 で す 。\n","エミ は 幸せ そう に 見え ま す 。\n","この 事実 を 心 に 留め て お い て 下さ い 。\n","彼女 は 私 たち の 世話 を し て くれ る 。\n","私 達 は 国際 人 に な り た い と 思 い ま す 。\n","約束 を 破 る べ き で は あ り ま せ ん 。\n","道路 を 横切 る とき は 車 に 注意 し なさ い 。\n","私 に は 生き 甲斐 が な い 。\n"],"name":"stdout"}]},{"metadata":{"id":"UbgN52WHAM7y","colab_type":"text"},"cell_type":"markdown","source":["それぞれの文章が英語-日本語で対応しているのがわかります。"]},{"metadata":{"id":"OQhfLZ5lAM7z","colab_type":"text"},"cell_type":"markdown","source":["## 1.1データの読み込みと単語の分割"]},{"metadata":{"id":"coc6DTCUAM71","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_data(file_path):\n","    # テキストファイルからデータを読み込むメソッド\n","    data = []\n","    for line in open(file_path, encoding='utf-8'):\n","        words = line.strip().split()  # スペースで単語を分割\n","        data.append(words)\n","    return data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z5UMnxsTAM74","colab_type":"code","colab":{}},"cell_type":"code","source":["train_X = load_data('./data/train.en')\n","train_Y = load_data('./data/train.ja')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ryYkPteoAM76","colab_type":"code","colab":{}},"cell_type":"code","source":["# 訓練データと検証データに分割\n","train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6yB4jwiCAM79","colab_type":"text"},"cell_type":"markdown","source":["この時点で入力と教師データは以下のようになっています"]},{"metadata":{"id":"0HV1SNLAAM7-","colab_type":"code","outputId":"128b752a-c263-4f49-b6d1-53b8e2c7d15c","executionInfo":{"status":"ok","timestamp":1552901692310,"user_tz":-540,"elapsed":34075,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["print('train data', train_X[0])\n","print('valid data', valid_X[0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["train data ['where', 'shall', 'we', 'eat', 'tonight', '?']\n","valid data ['you', 'may', 'extend', 'your', 'stay', 'in', 'tokyo', '.']\n"],"name":"stdout"}]},{"metadata":{"id":"NeB7llfIAM8E","colab_type":"text"},"cell_type":"markdown","source":["## 1.2単語辞書の作成\n","データセットに登場する各単語にIDを割り振る"]},{"metadata":{"id":"b-OqjDkXAM8F","colab_type":"code","colab":{}},"cell_type":"code","source":["# まず特殊トークンを定義しておく\n","PAD_TOKEN = '<PAD>'  # バッチ処理の際に、短い系列の末尾を埋めるために使う （Padding）\n","BOS_TOKEN = '<S>'  # 系列の始まりを表す （Beggining of sentence）\n","EOS_TOKEN = '</S>'  # 系列の終わりを表す （End of sentence）\n","UNK_TOKEN = '<UNK>'  # 語彙に存在しない単語を表す （Unknown）\n","PAD = 0\n","BOS = 1\n","EOS = 2\n","UNK = 3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T_G7dYnTAM8I","colab_type":"code","colab":{}},"cell_type":"code","source":["MIN_COUNT = 2  # 語彙に含める単語の最低出現回数 再提出現回数に満たない単語はUNKに置き換えられる\n","\n","# 単語をIDに変換する辞書の初期値を設定\n","word2id = {\n","    PAD_TOKEN: PAD,\n","    BOS_TOKEN: BOS,\n","    EOS_TOKEN: EOS,\n","    UNK_TOKEN: UNK,\n","    }\n","\n","# 単語辞書を作成\n","vocab_X = Vocab(word2id=word2id)\n","vocab_Y = Vocab(word2id=word2id)\n","vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n","vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0xDhdQ4FAM8K","colab_type":"code","outputId":"7ac8c6f8-27cb-4882-e2a3-2766e274a9d8","executionInfo":{"status":"ok","timestamp":1552901693074,"user_tz":-540,"elapsed":34815,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["vocab_size_X = len(vocab_X.id2word)\n","vocab_size_Y = len(vocab_Y.id2word)\n","print('入力言語の語彙数：', vocab_size_X)\n","print('出力言語の語彙数：', vocab_size_Y)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["入力言語の語彙数： 3725\n","出力言語の語彙数： 4405\n"],"name":"stdout"}]},{"metadata":{"id":"P-K_xHBkC5TC","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"NsoRIue9AM8P","colab_type":"text"},"cell_type":"markdown","source":["# 2.テンソルへの変換"]},{"metadata":{"id":"HsCajwO2AM8Q","colab_type":"text"},"cell_type":"markdown","source":["### 2.1 IDへの変換\n","まずはモデルが文章を認識できるように、文章を単語IDのリストに変換します"]},{"metadata":{"id":"gm6qa0fNAM8R","colab_type":"code","colab":{}},"cell_type":"code","source":["def sentence_to_ids(vocab, sentence):\n","    # 単語(str)のリストをID(int)のリストに変換する関数\n","    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n","    ids += [EOS]  # EOSを加える\n","    return ids"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lk0B0VR_AM8T","colab_type":"code","colab":{}},"cell_type":"code","source":["train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n","train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n","valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n","valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I4pEMlCxAM8X","colab_type":"text"},"cell_type":"markdown","source":["この時点で入力と教師データは以下のようになっている"]},{"metadata":{"id":"D6OKuYgwAM8Y","colab_type":"code","outputId":"2ad0f4da-88f6-4f37-c42e-207c9f5f5ca2","executionInfo":{"status":"ok","timestamp":1552901693698,"user_tz":-540,"elapsed":35425,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["print('train data', train_X[0])\n","print('valid data', valid_X[0])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["train data [132, 321, 28, 290, 367, 12, 2]\n","valid data [8, 93, 3532, 36, 236, 13, 284, 4, 2]\n"],"name":"stdout"}]},{"metadata":{"id":"_DlWrRnQAM8f","colab_type":"text"},"cell_type":"markdown","source":["### 2.2 DataLoaderの定義\n","データセットからバッチを取得するデータローダーを定義します\n","- この際、長さの異なる複数の系列をバッチで並列に扱えるように、短い系列の末尾を特定のシンボル（`<PAD>`など）でパディングし、バッチ内の系列の長さを最長のものに合わせる\n","- (batch_size, max_length)のサイズの行列を得るが、実際にモデルを学習させるときには、バッチをまたいで各時刻ごとに進めていくので、転置して(max_length, batch_size)の形に変える<br>（batch_first=Trueのオプションを使う場合は不要）"]},{"metadata":{"id":"YtmFgYLqAM8h","colab_type":"code","colab":{}},"cell_type":"code","source":["def pad_seq(seq, max_length):\n","    # 系列(seq)が指定の文長(max_length)になるように末尾をパディングする\n","    res = seq + [PAD for i in range(max_length - len(seq))]\n","    return res    \n","\n","\n","class DataLoader(object):\n","\n","    def __init__(self, X, Y, batch_size, shuffle=False):\n","        \"\"\"\n","        :param X: list, 入力言語の文章（単語IDのリスト）のリスト\n","        :param Y: list, 出力言語の文章（単語IDのリスト）のリスト\n","        :param batch_size: int, バッチサイズ\n","        :param shuffle: bool, サンプルの順番をシャッフルするか否か\n","        \"\"\"\n","        self.data = list(zip(X, Y))\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.start_index = 0\n","        \n","        self.reset()\n","    \n","    def reset(self):\n","        if self.shuffle:  # サンプルの順番をシャッフルする\n","            self.data = shuffle(self.data, random_state=random_state)\n","        self.start_index = 0  # ポインタの位置を初期化する\n","    \n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        # ポインタが最後まで到達したら初期化する\n","        if self.start_index >= len(self.data):\n","            self.reset()\n","            raise StopIteration()\n","\n","        # バッチを取得\n","        seqs_X, seqs_Y = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n","        # 入力系列seqs_Xの文章の長さ順（降順）に系列ペアをソートする\n","        seq_pairs = sorted(zip(seqs_X, seqs_Y), key=lambda p: len(p[0]), reverse=True)\n","        seqs_X, seqs_Y = zip(*seq_pairs)\n","        # 短い系列の末尾をパディングする\n","        lengths_X = [len(s) for s in seqs_X]  # 後述のEncoderのpack_padded_sequenceでも用いる\n","        lengths_Y = [len(s) for s in seqs_Y]\n","        max_length_X = max(lengths_X)\n","        max_length_Y = max(lengths_Y)\n","        padded_X = [pad_seq(s, max_length_X) for s in seqs_X]\n","        padded_Y = [pad_seq(s, max_length_Y) for s in seqs_Y]\n","        # tensorに変換し、転置する\n","        batch_X = torch.tensor(padded_X, dtype=torch.long, device=device).transpose(0, 1)\n","        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n","\n","        # ポインタを更新する\n","        self.start_index += self.batch_size\n","\n","        return batch_X, batch_Y, lengths_X"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-37frCXrAM8k","colab_type":"text"},"cell_type":"markdown","source":["# 3.モデルの構築\n","EncoderとDecoderのRNNを定義します。"]},{"metadata":{"id":"1X3oRjArAM8l","colab_type":"text"},"cell_type":"markdown","source":["### 導入：PackedSequence"]},{"metadata":{"id":"lRmj-EdbAM8m","colab_type":"text"},"cell_type":"markdown","source":["PyTorchのRNNでは、可変長の系列のバッチを効率よく計算できるように系列を表現する`PackedSequence`というクラスを用いることができます。\n","\n","入力バッチのテンソルをこの`PackedSequence`のインスタンスに変換してからRNNに入力することで、パディング部分の計算を省略することができるため、効率的な計算が可能になります。\n","\n","`PackedSequence`を作成するには、まず、系列長の異なるバッチに対してパディングを行なってください。\n","\n","ここで、パディングを行う前に各サンプルの系列長(`lengths`)を保存しておきます。"]},{"metadata":{"id":"yWAV3W89AM8n","colab_type":"code","outputId":"014a7150-ae3c-4ce1-aec0-3e070179c684","executionInfo":{"status":"ok","timestamp":1552901693702,"user_tz":-540,"elapsed":35420,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"cell_type":"code","source":["# 系列長がそれぞれ4,3,2の3つのサンプルからなるバッチを作成\n","batch = [[1,2,3,4], [5,6,7], [8,9]]\n","lengths = [len(sample) for sample in batch]\n","print('各サンプルの系列長:', lengths)\n","print()\n","\n","# 最大系列長に合うように各サンプルをpadding\n","_max_length = max(lengths)\n","padded = torch.tensor([pad_seq(sample, _max_length) for sample in batch])\n","print('paddingされたテンソル:\\n', padded)\n","padded = padded.transpose(0,1) # (max_length, batch_size)に転置\n","print('padding & 転置されたテンソル:\\n', padded)\n","print('padding & 転置されたテンソルのサイズ:\\n', padded.size())\n","print()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["各サンプルの系列長: [4, 3, 2]\n","\n","paddingされたテンソル:\n"," tensor([[ 1,  2,  3,  4],\n","        [ 5,  6,  7,  0],\n","        [ 8,  9,  0,  0]])\n","padding & 転置されたテンソル:\n"," tensor([[ 1,  5,  8],\n","        [ 2,  6,  9],\n","        [ 3,  7,  0],\n","        [ 4,  0,  0]])\n","padding & 転置されたテンソルのサイズ:\n"," torch.Size([4, 3])\n","\n"],"name":"stdout"}]},{"metadata":{"id":"GTAq1q8mAM8q","colab_type":"text"},"cell_type":"markdown","source":["次に、パディングを行ったテンソル(`padded`)と各サンプルの元々の系列長(`lengths`)を`torch.nn.utils.rnn.pack_padded_sequence`という関数に与えると、\n","`data`と`batch_sizes`という要素を持った`PackedSequence`のインスタンス(`packed`)が作成できます。\n","- `data`: テンソルの`PAD`以外の値のみを保有するベクトル\n","- `batch_sizes`: 各時刻で計算が必要な(=`PAD`に到達していない)バッチの数を表すベクトル"]},{"metadata":{"id":"FtRm7uqIAM8s","colab_type":"code","outputId":"77bb0b87-04ec-4e0b-cc53-2160ab64e29f","executionInfo":{"status":"ok","timestamp":1552901693703,"user_tz":-540,"elapsed":35413,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["# PackedSequenceに変換（テンソルをRNNに入力する前に適用する）\n","packed = pack_padded_sequence(padded, lengths=lengths) # 各サンプルの系列長も与える\n","print('PackedSequenceのインスタンス:\\n', packed) # テンソルのPAD以外の値(data)と各時刻で計算が必要な(=PADに到達していない)バッチの数(batch_sizes)を有するインスタンス\n","print()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["PackedSequenceのインスタンス:\n"," PackedSequence(data=tensor([ 1,  5,  8,  2,  6,  9,  3,  7,  4]), batch_sizes=tensor([ 3,  3,  2,  1]))\n","\n"],"name":"stdout"}]},{"metadata":{"id":"iYKaiMZDAM8w","colab_type":"text"},"cell_type":"markdown","source":["こうして得られた`PackedSequence`のインスタンスをRNNに入力します。（ここでは省略）\n","\n","RNNから出力されたテンソルは`PackedSeauence`のインスタンスのままなので、後段の計算につなぐために`torch.nn.utils.rnn.pad_packed_sequence`の関数によって通常のテンソルに戻します。"]},{"metadata":{"id":"F7BBaiVzAM8x","colab_type":"code","outputId":"36e0dbc1-393e-473c-acaa-f52a2056a635","executionInfo":{"status":"ok","timestamp":1552901694095,"user_tz":-540,"elapsed":35798,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"cell_type":"code","source":["# PackedSequenceのインスタンスをRNNに入力する（ここでは省略）\n","output = packed\n","\n","# テンソルに戻す(RNNの出力に対して適用する)\n","output, _length = pad_packed_sequence(output)  # PADを含む元のテンソルと各サンプルの系列長を返す\n","print('PADを含む元のテンソル:\\n', output)\n","print('各サンプルの系列長:', _length)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["PADを含む元のテンソル:\n"," tensor([[ 1,  5,  8],\n","        [ 2,  6,  9],\n","        [ 3,  7,  0],\n","        [ 4,  0,  0]])\n","各サンプルの系列長: tensor([ 4,  3,  2])\n"],"name":"stdout"}]},{"metadata":{"id":"wzT0I8w9AM81","colab_type":"text"},"cell_type":"markdown","source":["### Encoder\n","今回はEncoder側でバッチを処理する際に、`pack_padded_sequence`関数によってtensorを`PackedSequence`に変換し、処理を終えた後に`pad_packed_sequence`関数によってtensorに戻すという処理を行います。"]},{"metadata":{"id":"NdY2WGwMAM82","colab_type":"code","colab":{}},"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        \"\"\"\n","        :param input_size: int, 入力言語の語彙数\n","        :param hidden_size: int, 隠れ層のユニット数\n","        \"\"\"\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=PAD)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, seqs, input_lengths, hidden=None):\n","        \"\"\"\n","        :param seqs: tensor, 入力のバッチ, size=(max_length, batch_size)\n","        :param input_lengths: 入力のバッチの各サンプルの文長\n","        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n","        :return output: tensor, Encoderの出力, size=(max_length, batch_size, hidden_size)\n","        :return hidden: tensor, Encoderの隠れ状態, size=(1, batch_size, hidden_size)\n","        \"\"\"\n","        emb = self.embedding(seqs) # seqsはパディング済み\n","        packed = pack_padded_sequence(emb, input_lengths) # PackedSequenceオブジェクトに変換\n","        output, hidden = self.gru(packed, hidden)\n","        output, _ = pad_packed_sequence(output)\n","        return output, hidden"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eBw_ZiwDAM85","colab_type":"text"},"cell_type":"markdown","source":["### Decoder\n","今回はDecoder側ではパディング等行わないので、通常のtensorのままRNNに入力して問題ありません。"]},{"metadata":{"id":"UjKk_-9_AM86","colab_type":"code","colab":{}},"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        \"\"\"\n","        :param hidden_size: int, 隠れ層のユニット数\n","        :param output_size: int, 出力言語の語彙数\n","        :param dropout: float, ドロップアウト率\n","        \"\"\"\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, seqs, hidden):\n","        \"\"\"\n","        :param seqs: tensor, 入力のバッチ, size=(1, batch_size)\n","        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n","        :return output: tensor, Decoderの出力, size=(1, batch_size, output_size)\n","        :return hidden: tensor, Decoderの隠れ状態, size=(1, batch_size, hidden_size)\n","        \"\"\"\n","        emb = self.embedding(seqs)\n","        output, hidden = self.gru(emb, hidden)\n","        output = self.out(output)\n","        return output, hidden"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tf64KCf2AM88","colab_type":"text"},"cell_type":"markdown","source":["## EncoderDecoder\n","上で定義したEncoderとDecoderを用いた、一連の処理をまとめるEncoderDecoderのクラスを定義します。\n","\n","ここで、Decoder側の処理で注意する点があります。\n","\n","RNNでは、時刻$t$の出力を時刻$t+1$の入力とすることができるが、この方法でDecoderを学習させると連鎖的に誤差が大きくなっていき、学習が不安定になったり収束が遅くなったりする問題が発生します。\n","\n","\n","この問題への対策として**Teacher Forcing**というテクニックがあります。\n","これは、訓練時にはDecoder側の入力に、ターゲット系列（参照訳）をそのまま使うというものです。\n","これにより学習が安定し、収束が早くなるというメリットがありますが、逆に評価時は前の時刻にDecoderが生成したものが使われるため、学習時と分布が異なってしまうというデメリットもあります。\n","\n","\n","Teacher Forcingの拡張として、ターゲット系列を入力とするか生成された結果を入力とするかを確率的にサンプリングする**Scheduled Sampling**という手法があります。\n","\n","ここではScheduled Samplingを採用し、一定の確率に基づいてターゲット系列を入力とするか生成された結果を入力とするかを切り替えられるようにクラスを定義しておきます。"]},{"metadata":{"id":"OB9Nlcd9AM89","colab_type":"code","colab":{}},"cell_type":"code","source":["class EncoderDecoder(nn.Module):\n","    \"\"\"EncoderとDecoderの処理をまとめる\"\"\"\n","    def __init__(self, input_size, output_size, hidden_size):\n","        \"\"\"\n","        :param input_size: int, 入力言語の語彙数\n","        :param output_size: int, 出力言語の語彙数\n","        :param hidden_size: int, 隠れ層のユニット数\n","        \"\"\"\n","        super(EncoderDecoder, self).__init__()\n","        self.encoder = Encoder(input_size, hidden_size)\n","        self.decoder = Decoder(hidden_size, output_size)\n","\n","    def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n","        \"\"\"\n","        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n","        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n","        :param max_length: int, Decoderの最大文長\n","        :param batch_Y: tensor, Decoderで用いるターゲット系列\n","        :param use_teacher_forcing: Decoderでターゲット系列を入力とするフラグ\n","        :return decoder_outputs: tensor, Decoderの出力, \n","            size=(max_length, batch_size, self.decoder.output_size)\n","        \"\"\"\n","        # encoderに系列を入力（複数時刻をまとめて処理）\n","        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n","        \n","        _batch_size = batch_X.size(1)\n","\n","        # decoderの入力と隠れ層の初期状態を定義\n","        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device) # 最初の入力にはBOSを使用する\n","        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n","        decoder_hidden = encoder_hidden  # Encoderの最終隠れ状態を取得\n","\n","        # decoderの出力のホルダーを定義\n","        decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device) # max_length分の固定長\n","\n","        # 各時刻ごとに処理\n","        for t in range(max_length):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","            decoder_outputs[t] = decoder_output\n","            # 次の時刻のdecoderの入力を決定\n","            if use_teacher_forcing and batch_Y is not None:  # teacher forceの場合、ターゲット系列を用いる\n","                decoder_input = batch_Y[t].unsqueeze(0)\n","            else:  # teacher forceでない場合、自身の出力を用いる\n","                decoder_input = decoder_output.max(-1)[1]\n","                \n","        return decoder_outputs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qBTFmbwLAM9A","colab_type":"text"},"cell_type":"markdown","source":["# 4.訓練\n","### 4.1 損失関数の定義\n","基本的にはクロスエントロピーを損失関数として用いますが、パディングを行うと短い系列の末尾には`<PAD>`トークンが入るため、この部分の損失を計算しないように、マスクをかけます。"]},{"metadata":{"id":"Kt-r-nxJAM9B","colab_type":"code","colab":{}},"cell_type":"code","source":["mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD) # PADを無視する\n","def masked_cross_entropy(logits, target):\n","    logits_flat = logits.view(-1, logits.size(-1)) # (max_seq_len * batch_size, output_size)\n","    target_flat = target.view(-1) # (max_seq_len * batch_size, 1)\n","    return mce(logits_flat, target_flat)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GgQZl0GvAM9E","colab_type":"text"},"cell_type":"markdown","source":["### 4.2学習"]},{"metadata":{"id":"qurGD8IsAM9F","colab_type":"code","colab":{}},"cell_type":"code","source":["# ハイパーパラメータの設定\n","num_epochs = 10\n","batch_size = 64\n","lr = 1e-3  # 学習率\n","teacher_forcing_rate = 0.2  # Teacher Forcingを行う確率\n","ckpt_path = 'model.pth'  # 学習済みのモデルを保存するパス\n","\n","model_args = {\n","    'input_size': vocab_size_X,\n","    'output_size': vocab_size_Y,\n","    'hidden_size': 256,\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4xNxWJGPAM9I","colab_type":"code","colab":{}},"cell_type":"code","source":["# データローダを定義\n","train_dataloader = DataLoader(train_X, train_Y, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_X, valid_Y, batch_size=batch_size, shuffle=False)\n","\n","# モデルとOptimizerを定義\n","model = EncoderDecoder(**model_args).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_67wGmARAM9L","colab_type":"text"},"cell_type":"markdown","source":["実際に損失関数を計算する関数を定義します。"]},{"metadata":{"id":"Adggq9xOAM9L","colab_type":"code","colab":{}},"cell_type":"code","source":["def compute_loss(batch_X, batch_Y, lengths_X, model, optimizer=None, is_train=True):\n","    # 損失を計算する関数\n","    model.train(is_train)  # train/evalモードの切替え\n","    \n","    # 一定確率でTeacher Forcingを行う\n","    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n","    max_length = batch_Y.size(0)\n","    # 推論\n","    pred_Y = model(batch_X, lengths_X, max_length, batch_Y, use_teacher_forcing)\n","    \n","    # 損失関数を計算\n","    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n","    \n","    if is_train:  # 訓練時はパラメータを更新\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n","    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n","\n","    return loss.item(), batch_Y, pred"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QHJXFnLpAM9O","colab_type":"text"},"cell_type":"markdown","source":["ここで、Loss以外に、学習の進捗を確認するためにモデルの性能を評価する指標として、BLEUを計算します。\n","\n","BLEUは機械翻訳の分野において最も一般的な自動評価基準の一つで、予め用意した複数の参照訳と、機械翻訳モデルが出力した訳のn-gramのマッチ率に基づく指標です。\n","\n","NLTK (Natural Language Tool Kit) という自然言語処理で用いられるライブラリを用いて簡単に計算することができます。"]},{"metadata":{"id":"ImK-xzAWAM9P","colab_type":"code","colab":{}},"cell_type":"code","source":["def calc_bleu(refs, hyps):\n","    \"\"\"\n","    BLEUスコアを計算する関数\n","    :param refs: list, 参照訳。単語のリストのリスト (例： [['I', 'have', 'a', 'pen'], ...])\n","    :param hyps: list, モデルの生成した訳。単語のリストのリスト (例： ['I', 'have', 'a', 'pen'])\n","    :return: float, BLEUスコア(0~100)\n","    \"\"\"\n","    refs = [[ref[:ref.index(EOS)]] for ref in refs] # EOSは評価しないで良いので切り捨てる, refsのほうは複数なのでlistが一個多くかかっている\n","    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n","    return 100 * bleu_score.corpus_bleu(refs, hyps)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"inYRxu8aAM9T","colab_type":"text"},"cell_type":"markdown","source":["それではモデルの訓練を行います。"]},{"metadata":{"id":"bz-Dx5p6AM9T","colab_type":"code","outputId":"c27709f2-7acc-4c42-da07-43aac6b39436","executionInfo":{"status":"ok","timestamp":1552902111771,"user_tz":-540,"elapsed":453455,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"cell_type":"code","source":["# 訓練\n","best_valid_bleu = 0.\n","\n","for epoch in range(1, num_epochs+1):\n","    train_loss = 0.\n","    train_refs = []\n","    train_hyps = []\n","    valid_loss = 0.\n","    valid_refs = []\n","    valid_hyps = []\n","    # train\n","    for batch in train_dataloader:\n","        batch_X, batch_Y, lengths_X = batch\n","        loss, gold, pred = compute_loss(\n","            batch_X, batch_Y, lengths_X, model, optimizer, \n","            is_train=True\n","            )\n","        train_loss += loss\n","        train_refs += gold\n","        train_hyps += pred\n","    # valid\n","    for batch in valid_dataloader:\n","        batch_X, batch_Y, lengths_X = batch\n","        loss, gold, pred = compute_loss(\n","            batch_X, batch_Y, lengths_X, model, \n","            is_train=False\n","            )\n","        valid_loss += loss\n","        valid_refs += gold\n","        valid_hyps += pred\n","    # 損失をサンプル数で割って正規化\n","    train_loss = np.sum(train_loss) / len(train_dataloader.data)\n","    valid_loss = np.sum(valid_loss) / len(valid_dataloader.data)\n","    # BLEUを計算\n","    train_bleu = calc_bleu(train_refs, train_hyps)\n","    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n","\n","    # validationデータでBLEUが改善した場合にはモデルを保存\n","    if valid_bleu > best_valid_bleu:\n","        ckpt = model.state_dict()\n","        torch.save(ckpt, ckpt_path)\n","        best_valid_bleu = valid_bleu\n","\n","    print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n","            epoch, train_loss, train_bleu, valid_loss, valid_bleu))\n","        \n","    print('-'*80)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Epoch 1: train_loss: 52.42  train_bleu: 3.36  valid_loss: 49.08  valid_bleu: 4.48\n","--------------------------------------------------------------------------------\n","Epoch 2: train_loss: 44.71  train_bleu: 7.23  valid_loss: 44.78  valid_bleu: 6.89\n","--------------------------------------------------------------------------------\n","Epoch 3: train_loss: 40.48  train_bleu: 10.89  valid_loss: 42.31  valid_bleu: 10.82\n","--------------------------------------------------------------------------------\n","Epoch 4: train_loss: 37.40  train_bleu: 13.89  valid_loss: 41.16  valid_bleu: 13.29\n","--------------------------------------------------------------------------------\n","Epoch 5: train_loss: 34.86  train_bleu: 16.72  valid_loss: 40.16  valid_bleu: 12.71\n","--------------------------------------------------------------------------------\n","Epoch 6: train_loss: 33.07  train_bleu: 19.05  valid_loss: 40.45  valid_bleu: 17.01\n","--------------------------------------------------------------------------------\n","Epoch 7: train_loss: 31.96  train_bleu: 20.26  valid_loss: 39.89  valid_bleu: 15.55\n","--------------------------------------------------------------------------------\n","Epoch 8: train_loss: 30.13  train_bleu: 22.96  valid_loss: 40.13  valid_bleu: 16.61\n","--------------------------------------------------------------------------------\n","Epoch 9: train_loss: 28.93  train_bleu: 24.88  valid_loss: 40.33  valid_bleu: 16.69\n","--------------------------------------------------------------------------------\n","Epoch 10: train_loss: 28.42  train_bleu: 25.78  valid_loss: 40.21  valid_bleu: 16.31\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"metadata":{"id":"Y3tlT8z9SCoF","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"BdgBkAlkAM9V","colab_type":"text"},"cell_type":"markdown","source":["# 5.評価"]},{"metadata":{"id":"ze8jkchYAM9W","colab_type":"code","outputId":"d461a30a-bbe0-4e71-9653-3c29d60e5e7b","executionInfo":{"status":"ok","timestamp":1552902111775,"user_tz":-540,"elapsed":453446,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["# 学習済みモデルの読み込み\n","ckpt = torch.load(ckpt_path) # cpuで処理する場合はmap_locationで指定する必要があります。\n","model.load_state_dict(ckpt)\n","model.eval()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoder(\n","  (encoder): Encoder(\n","    (embedding): Embedding(3725, 256, padding_idx=0)\n","    (gru): GRU(256, 256)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(4405, 256, padding_idx=0)\n","    (gru): GRU(256, 256)\n","    (out): Linear(in_features=256, out_features=4405, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":35}]},{"metadata":{"id":"YyKW9WY6AM9Y","colab_type":"code","colab":{}},"cell_type":"code","source":["def ids_to_sentence(vocab, ids):\n","    # IDのリストを単語のリストに変換する\n","    return [vocab.id2word[_id] for _id in ids]\n","\n","def trim_eos(ids):\n","    # IDのリストからEOS以降の単語を除外する\n","    if EOS in ids:\n","        return ids[:ids.index(EOS)]\n","    else:\n","        return ids"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r7qCpnSpAM9b","colab_type":"code","colab":{}},"cell_type":"code","source":["# テストデータの読み込み\n","test_X = load_data('./data/dev.en')\n","test_Y = load_data('./data/dev.ja')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"41hLJdkNAM9d","colab_type":"code","colab":{}},"cell_type":"code","source":["test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n","test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IFK0JzSYAM9m","colab_type":"code","colab":{}},"cell_type":"code","source":["test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mYfjq3shAM9q","colab_type":"code","outputId":"1ea9aadc-9409-401e-a3e2-430ffe8ea432","executionInfo":{"status":"ok","timestamp":1552902111786,"user_tz":-540,"elapsed":453436,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["# 生成\n","batch_X, batch_Y, lengths_X = next(test_dataloader)\n","sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n","sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n","print('src: {}'.format(sentence_X))\n","print('tgt: {}'.format(sentence_Y))\n","\n","output = model(batch_X, lengths_X, max_length=20)\n","output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n","output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n","output_sentence_without_trim = ' '.join(ids_to_sentence(vocab_Y, output))\n","print('out: {}'.format(output_sentence))\n","print('without trim: {}'.format(output_sentence_without_trim))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["src: show your own business .\n","tgt: 自分 の 事 を しろ 。\n","out: 自分 の 仕事 を <UNK> し て い 。\n","without trim: 自分 の 仕事 を <UNK> し て い 。 </S> </S> </S> </S> </S> </S> </S> </S> </S> </S> </S>\n"],"name":"stdout"}]},{"metadata":{"id":"atSEiLMHAM93","colab_type":"code","outputId":"cc5685db-97db-42df-927e-8e2729243a0f","executionInfo":{"status":"ok","timestamp":1552902117735,"user_tz":-540,"elapsed":459370,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# BLEUの計算\n","test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)\n","refs_list = []\n","hyp_list = []\n","\n","for batch in test_dataloader:\n","    batch_X, batch_Y, lengths_X = batch\n","    pred_Y = model(batch_X, lengths_X, max_length=20)\n","    pred = pred_Y.max(dim=-1)[1].view(-1).data.cpu().tolist()\n","    refs = batch_Y.view(-1).data.cpu().tolist()\n","    refs_list.append(refs)\n","    hyp_list.append(pred)\n","bleu = calc_bleu(refs_list, hyp_list)\n","print(bleu)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["16.08479765444376\n"],"name":"stdout"}]},{"metadata":{"id":"B1UDdsNvruEi","colab_type":"text"},"cell_type":"markdown","source":["### Beam Search\n","テストデータに対して新たな文を生成する際、これまでは各時刻で最も確率の高い単語を正解として採用し、次のステップでの入力として使っていました。\n","ただ、本当にやりたいのは、文全体の尤度が最も高くなるような文を生成することです。そのため、ただ近視眼的に確率の高い単語を採用していくより、もう少し大局的に評価していく必要があります。\n","\n","Beam Searchでは、各時刻において一定の数$K$のそれまでのスコア(対数尤度など)の高い文を保持しながら選択を行っていきます。  \n","\n","\n","図はSlack上のものを参照してください。"]},{"metadata":{"id":"2vFRiqFwtKsZ","colab_type":"code","colab":{}},"cell_type":"code","source":["class BeamEncoderDecoder(EncoderDecoder):\n","    \"\"\"\n","    Beam Searchでdecodeを行うためのクラス\n","    \"\"\"\n","    def __init__(self, input_size, output_size, hidden_size, beam_size=4):\n","        \"\"\"\n","        :param input_size: int, 入力言語の語彙数\n","        :param output_size: int, 出力言語の語彙数\n","        :param hidden_size: int, 隠れ層のユニット数\n","        :param beam_size: int, ビーム数\n","        \"\"\"\n","        super(BeamEncoderDecoder, self).__init__(input_size, output_size, hidden_size)\n","        self.beam_size = beam_size\n","\n","    def forward(self, batch_X, lengths_X, max_length):\n","        \"\"\"\n","        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n","        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n","        :param max_length: int, Decoderの最大文長\n","        :return decoder_outputs: list, 各ビームのDecoderの出力\n","        :return finished_scores: list of float, 各ビームのスコア\n","        \"\"\"\n","        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n","\n","        # decoderの入力と隠れ層の初期状態を定義\n","        decoder_input = torch.tensor([BOS] * self.beam_size, dtype=torch.long, device=device)\n","        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n","        decoder_hidden = encoder_hidden\n","\n","        # beam_sizeの数だけrepeatする\n","        decoder_input = decoder_input.expand(1, beam_size)\n","        decoder_hidden = decoder_hidden.expand(1, beam_size, -1).contiguous()\n","\n","        k = beam_size\n","        finished_beams = []\n","        finished_scores = []\n","        prev_probs = torch.zeros(beam_size, 1, dtype=torch.float, device=device)  # 前の時刻の各ビームの対数尤度を保持しておく\n","        output_size = self.decoder.output_size\n","\n","        # 各時刻ごとに処理\n","        for t in range(max_length):\n","            # decoder_input: (1, k)\n","            decoder_output, decoder_hidden = self.decoder(decoder_input[-1:], decoder_hidden)\n","            # decoder_output: (1, k, output_size)\n","            # decoder_hidden: (1, k, hidden_size)\n","            decoder_output_t = decoder_output[-1]  # (k, output_size)\n","            log_probs = prev_probs + F.log_softmax(decoder_output_t, dim=-1)  # (k, output_size)\n","            scores = log_probs  # 対数尤度をスコアとする\n","\n","            # スコアの高いビームとその単語を取得\n","            flat_scores = scores.view(-1)  # (k*output_size,)\n","            if t == 0:\n","                flat_scores = flat_scores[:output_size]  # t=0のときは後半の同じ値の繰り返しを除外\n","            top_vs, top_is = flat_scores.data.topk(k)\n","            beam_indices = top_is / output_size  # (k,)\n","            word_indices = top_is % output_size  # (k,)\n","            \n","            # ビームを更新する\n","            _next_beam_indices = []\n","            _next_word_indices = []\n","            for b, w in zip(beam_indices, word_indices):\n","                if w.item() == EOS:  # EOSに到達した場合はそのビームは更新して終了\n","                    k -= 1\n","                    beam = torch.cat([decoder_input.t()[b], w.view(1,)])  # (t+2,)\n","                    score = scores[b, w].item()\n","                    finished_beams.append(beam)\n","                    finished_scores.append(score)\n","                else:   # それ以外の場合はビームを更新\n","                    _next_beam_indices.append(b)\n","                    _next_word_indices.append(w)\n","            if k == 0:\n","                break\n","\n","            # tensorｎに変換\n","            next_beam_indices = torch.tensor(_next_beam_indices, device=device)\n","            next_word_indices = torch.tensor(_next_word_indices, device=device)\n","\n","            # 次の時刻のDecoderの入力を更新\n","            decoder_input = torch.index_select(\n","                decoder_input, dim=-1, index=next_beam_indices)\n","            decoder_input = torch.cat(\n","                [decoder_input, next_word_indices.unsqueeze(0)], dim=0)\n","    \n","            # 次の時刻のDecoderの隠れ層を更新\n","            decoder_hidden = torch.index_select(\n","                decoder_hidden, dim=1, index=next_beam_indices)\n","\n","            # 各ビームの対数尤度を更新\n","            flat_probs = log_probs.view(-1)  # (k*output_size,)\n","            next_indices = (next_beam_indices + 1) * next_word_indices\n","            prev_probs = torch.index_select(\n","                flat_probs, dim=0, index=next_indices).unsqueeze(1)  # (k, 1)\n","\n","        # すべてのビームが完了したらデータを整形\n","        decoder_outputs = [[idx.item() for idx in beam[1:-1]] for beam in finished_beams]\n","        \n","        return decoder_outputs, finished_scores"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DIZ9NHXHttCg","colab_type":"code","outputId":"5b101fc9-0c43-478d-86cb-0a6e1145fcf1","executionInfo":{"status":"ok","timestamp":1552902117739,"user_tz":-540,"elapsed":459356,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["# 学習済みモデルの読み込み\n","beam_size = 3\n","beam_model = BeamEncoderDecoder(**model_args, beam_size=beam_size).to(device)\n","beam_model.load_state_dict(ckpt)\n","beam_model.eval()"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BeamEncoderDecoder(\n","  (encoder): Encoder(\n","    (embedding): Embedding(3725, 256, padding_idx=0)\n","    (gru): GRU(256, 256)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(4405, 256, padding_idx=0)\n","    (gru): GRU(256, 256)\n","    (out): Linear(in_features=256, out_features=4405, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":43}]},{"metadata":{"id":"KzsI_6bBtwGc","colab_type":"code","colab":{}},"cell_type":"code","source":["test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iSr_wwtbtxKZ","colab_type":"code","outputId":"9b85073d-0dc1-42bb-c158-b5715f25ca57","executionInfo":{"status":"ok","timestamp":1552902117742,"user_tz":-540,"elapsed":459346,"user":{"displayName":"鈴木航介","photoUrl":"","userId":"00468427838777565972"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["# 生成\n","batch_X, batch_Y, lengths_X = next(test_dataloader)\n","sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n","sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n","print('src: {}'.format(sentence_X))\n","print('tgt: {}'.format(sentence_Y))\n","\n","# 普通のdecode\n","output = model(batch_X, lengths_X, max_length=20)\n","output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n","output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n","print('out: {}'.format(output_sentence))\n","\n","# beam decode\n","outputs, scores = beam_model(batch_X, lengths_X, max_length=20)\n","# scoreの良い順にソート\n","outputs, scores = zip(*sorted(zip(outputs, scores), key=lambda x: -x[1]))\n","for o, output in enumerate(outputs):\n","    output_sentence = ' '.join(ids_to_sentence(vocab_Y, output))\n","    print('out{}: {}'.format(o+1, output_sentence))    "],"execution_count":45,"outputs":[{"output_type":"stream","text":["src: show your own business .\n","tgt: 自分 の 事 を しろ 。\n","out: 自分 の 仕事 を <UNK> し て い 。\n","out1: 自分 の 仕事 を <UNK> し て\n","out2: 自分 の 仕事 を <UNK> し て 。\n","out3: 自分 の 仕事 を <UNK> し て 。 。\n"],"name":"stdout"}]},{"metadata":{"id":"roOpX8nAAM95","colab_type":"text"},"cell_type":"markdown","source":["# 参考文献\n","- [Practical PyTorch: Translation with a Sequence to Sequence Network and Attention](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb)\n","- [Translation with a Sequence to Sequence Network and Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py)\n","- [Encoder\\-decoderモデルとTeacher Forcing，Scheduled Sampling，Professor Forcing](http://satopirka.com/2018/02/encoder-decoder%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A8teacher-forcingscheduled-samplingprofessor-forcing/)\n","- [Sequence\\-to\\-Sequence Learning as Beam\\-Search Optimization](https://arxiv.org/abs/1606.02960)"]}]}